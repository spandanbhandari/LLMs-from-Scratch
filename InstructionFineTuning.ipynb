{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWduNiLvTl7DQu32o1tW8h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spandanbhandari/LLMs-from-Scratch/blob/main/InstructionFineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkSGGVi_rra1",
        "outputId": "220c6e56-6e1f-46b1-d84b-e87c0b2307dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "def download_and_load_file(file_path, url):\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:                                                #1\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "    with open(file_path, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        " )\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example Entry:\\n\",data[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blBhh2kXsBnL",
        "outputId": "bfcbcbe0-2bcb-4591-bb7d-cd5b05719b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "  instruction_text=(\n",
        "      f\"Below is an instruction that describes a task.\"\n",
        "      f\"Write a response that appropriately completes the request.\"\n",
        "      f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "  )\n",
        "  input_text=(\n",
        "      f\"\\n\\n### Input:\\n{entry['input']}\"\n",
        "      if entry[\"input\"]  else \"\"\n",
        "  )\n",
        "  return instruction_text+input_text"
      ],
      "metadata": {
        "id": "jzuKkcotsrU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input=format_input(data[50])\n",
        "desired_response=f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "print(model_input+desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1UKYg1_tUr_",
        "outputId": "dc06b5ec-7877-4b21-927f-2b145882e38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_input=format_input(data[999])\n",
        "desired_response=f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "print(model_input+desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP8ZWenXtyRf",
        "outputId": "f655e6c1-a43b-4d5e-b949-68604f579a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion=int(len(data)*0.85)\n",
        "test_portion=int(len(data)*0.1)\n",
        "val_portion=len(data)-train_portion-test_portion\n",
        "\n",
        "train_data=data[:train_portion]\n",
        "test_data=data[train_portion:train_portion+test_portion]\n",
        "val_data=data[train_portion+test_portion:]\n",
        "\n",
        "print(\"Number of training examples:\", len(train_data))\n",
        "print(\"Number of testing examples:\", len(test_data))\n",
        "print(\"Number of validation examples:\", len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzWzQ3-Et__4",
        "outputId": "afd9eafb-cac2-4131-f89c-95a0ef894c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 935\n",
            "Number of testing examples: 110\n",
            "Number of validation examples: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.encoded_texts=[]\n",
        "        for entry in data:\n",
        "          instruction_plus_input=format_input(entry)\n",
        "          response_text=f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "          full_text=instruction_plus_input+response_text\n",
        "          self.encoded_texts.append(tokenizer.encode(full_text))\n",
        "    def __getitem__(self, index):\n",
        "      return self.encoded_texts[index]\n",
        "    def __len__(self):\n",
        "      return len(self.data)"
      ],
      "metadata": {
        "id": "sD-DAzAuvHaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEz0LLngwAVq",
        "outputId": "f3e06846-4ee5-407d-8866-493cf718de6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\",allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEiKzfNdv0hK",
        "outputId": "4283534a-0183-41ef-b6dc-7e90fbb532dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "  batch_max_length=max(len(item)+1 for item in batch)\n",
        "  inputs_lst=[]\n",
        "\n",
        "  for item in batch:\n",
        "    new_item=item.copy()\n",
        "    new_item+=[pad_token_id]\n",
        "\n",
        "    padded=(\n",
        "        new_item+[pad_token_id]*(batch_max_length-len(new_item))\n",
        "    )\n",
        "    inputs=torch.tensor(padded[:-1])\n",
        "    inputs_lst.append(inputs)\n",
        "\n",
        "  inputs_tensor=torch.stack(inputs_lst).to(device)\n",
        "  return inputs_tensor"
      ],
      "metadata": {
        "id": "wX7hmP6Cwc2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        " )\n",
        "print(custom_collate_draft_1(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-iKhWu3xFJW",
        "outputId": "c3b99efd-fd90-42e5-ae88-6d245fa03c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "  batch_max_length=max(len(item)+1 for item in batch)\n",
        "  inputs_lst,targets_lst=[],[]\n",
        "  for item in batch:\n",
        "    new_item=item.copy()\n",
        "    new_item+=[pad_token_id]\n",
        "    padded=(\n",
        "        new_item+[pad_token_id]*(batch_max_length-len(new_item))\n",
        "    )\n",
        "    inputs=torch.tensor(padded[:-1])\n",
        "    targets=torch.tensor(padded[1:])\n",
        "    inputs_lst.append(inputs)\n",
        "    targets_lst.append(targets)\n",
        "  inputs_tensor=torch.stack(inputs_lst).to(device)\n",
        "  targets_tensor=torch.stack(targets_lst).to(device)\n",
        "  return inputs_tensor,targets_tensor\n",
        "inputs,targets=custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDrsNONnxe-q",
        "outputId": "0c475d1d-950d-4b5e-aae9-48cd4e66b8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "  batch_max_length=max(len(item)+1 for item in batch)\n",
        "  inputs_lst,targets_lst=[],[]\n",
        "\n",
        "  for item in batch:\n",
        "    new_item=item.copy()\n",
        "    new_item+=[pad_token_id]\n",
        "\n",
        "    padded=(\n",
        "        new_item+[pad_token_id]*(batch_max_length-len(new_item))\n",
        "    )\n",
        "    inputs=torch.tensor(padded[:-1])\n",
        "    targets=torch.tensor(padded[1:])\n",
        "\n",
        "    mask=targets==pad_token_id\n",
        "    indices=torch.nonzero(mask).squeeze()\n",
        "    if indices.numel()>1:\n",
        "      targets[indices[1:]]=ignore_index\n",
        "    if allowed_max_length is not None:\n",
        "      inputs=inputs[:allowed_max_length]\n",
        "      targets=targets[:allowed_max_length]\n",
        "    inputs_lst.append(inputs)\n",
        "    targets_lst.append(targets)\n",
        "  inputs_tensor=torch.stack(inputs_lst).to(device)\n",
        "  targets_tensor=torch.stack(targets_lst).to(device)\n",
        "  return inputs_tensor,targets_tensor"
      ],
      "metadata": {
        "id": "F4RFwbE7yYNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs,targets=custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwViMQBNzbEq",
        "outputId": "bb30cdb3-a7c6-4ee9-85b2-bd85402cf944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\",device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4sExhwg0MT7",
        "outputId": "926558be-830f-4f9c-ec8b-a99b07d5b1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn=partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ],
      "metadata": {
        "id": "OMkYSUGN0YiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers=0\n",
        "batch_size=8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_dataset=InstructionDataset(train_data,tokenizer)\n",
        "train_loader=DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "val_dataset=InstructionDataset(val_data,tokenizer)\n",
        "val_loader=DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "test_dataset=InstructionDataset(test_data,tokenizer)\n",
        "test_loader=DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "Gv231AYN0h1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Loader:\")\n",
        "for inputs,targets in train_loader:\n",
        "  print(inputs.shape,targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cE7VylW1HEG",
        "outputId": "1a1544dd-160f-4a1c-9af1-8d93029cb15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([7, 72]) torch.Size([7, 72])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llms-from-scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaFRuwnE1qz1",
        "outputId": "dbb2fbb6-4587-4301-c573-ab25b6baced5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llms-from-scratch\n",
            "  Downloading llms_from_scratch-1.0.6-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.6.0+cu124)\n",
            "Collecting jupyterlab>=4.0 (from llms-from-scratch)\n",
            "  Downloading jupyterlab-4.4.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (3.10.0)\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.18.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (4.67.1)\n",
            "Requirement already satisfied: numpy<2.1,>=1.26 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.2.2)\n",
            "Collecting pip>=25.0.1 (from llms-from-scratch)\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pytest>=8.3.5 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (8.3.5)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (24.2)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=8.3.5->llms-from-scratch) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=8.3.5->llms-from-scratch) (1.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.32.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.37.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->llms-from-scratch) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.3.0->llms-from-scratch) (1.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->llms-from-scratch) (0.45.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab>=4.0->llms-from-scratch) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab>=4.0->llms-from-scratch) (4.3.7)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (4.23.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->llms-from-scratch) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->llms-from-scratch) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->llms-from-scratch) (3.1.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (21.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (3.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.8.4)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (24.11.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading llms_from_scratch-1.0.6-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.2-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, pip, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, fqdn, async-lru, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, arrow, nvidia-cusolver-cu12, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, llms-from-scratch\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 6.5.7 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n",
            "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.5 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.2 jupyterlab-server-2.27.3 llms-from-scratch-1.0.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 overrides-7.7.0 pip-25.1.1 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch05 import download_and_load_gpt2\n",
        "from llms_from_scratch.ch04 import GPTModel\n",
        "from llms_from_scratch.ch05 import load_weights_into_gpt\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        " }\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        " }\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        " )\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpx_yf-_aSX0",
        "outputId": "ffb191cf-01a5-436d-f373-ae994512bc76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 113kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 523kiB/s]\n",
            "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 141kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [07:23<00:00, 3.20MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 12.5MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 581kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 327kiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "input_text=format_input(val_data[0])\n",
        "print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuBErhxLbeF-",
        "outputId": "34694f60-3389-44fa-d209-c299b9a7e14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch05 import generate,text_to_token_ids,token_ids_to_text\n",
        "token_ids=generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text,tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text=token_ids_to_text(token_ids,tokenizer)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6gdM16GdgeT",
        "outputId": "bc75a902-0c7c-4a4b-adbf-3f30e2887a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_text=generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKtIg_QSeCQf",
        "outputId": "c2239690-bfd0-421c-dc20-7bbf79c7f9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch05 import (\n",
        "    calc_loss_loader,\n",
        "    train_model_simple\n",
        ")"
      ],
      "metadata": {
        "id": "D9ng1ooBe_nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "with torch.no_grad():\n",
        "  train_loss=calc_loss_loader(\n",
        "      train_loader,model,device,num_batches=5\n",
        "  )\n",
        "  val_loss=calc_loss_loader(\n",
        "      val_loader,model,device,num_batches=5\n",
        "  )\n",
        "print(f\"Train Loss: {train_loss:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ase_1V9fEXY",
        "outputId": "7ef4ab6e-9e43-4b26-abba-effed6bc8ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 4.0136\n",
            "Validation Loss: 3.9385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time=time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer=torch.optim.AdamW(\n",
        "    model.parameters(),lr=0.00005,weight_decay=0.1\n",
        ")\n",
        "num_epochs=2\n",
        "train_losses,val_losses,tokens_seen=train_model_simple(\n",
        "    model,train_loader,val_loader,optimizer,device,num_epochs=num_epochs,eval_freq=5,eval_iter=5,start_context=format_input(val_data[0]),tokenizer=tokenizer\n",
        ")\n",
        "end_time=time.time()\n",
        "execution_time_minutes=(end_time-start_time)/60\n",
        "print(f\"Execution Time: {execution_time_minutes:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF5vROYxfdxc",
        "outputId": "6206f3a3-3138-46fc-d69e-885d0302c39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.776, Val loss 2.755\n",
            "Ep 1 (Step 000005): Train loss 1.207, Val loss 1.138\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.968\n",
            "Ep 1 (Step 000015): Train loss 0.856, Val loss 0.907\n",
            "Ep 1 (Step 000020): Train loss 0.788, Val loss 0.910\n",
            "Ep 1 (Step 000025): Train loss 0.774, Val loss 0.866\n",
            "Ep 1 (Step 000030): Train loss 0.801, Val loss 0.841\n",
            "Ep 1 (Step 000035): Train loss 0.716, Val loss 0.812\n",
            "Ep 1 (Step 000040): Train loss 0.669, Val loss 0.801\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.790\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.763, Val loss 0.771\n",
            "Ep 1 (Step 000060): Train loss 0.720, Val loss 0.748\n",
            "Ep 1 (Step 000065): Train loss 0.651, Val loss 0.739\n",
            "Ep 1 (Step 000070): Train loss 0.530, Val loss 0.732\n",
            "Ep 1 (Step 000075): Train loss 0.566, Val loss 0.731\n",
            "Ep 1 (Step 000080): Train loss 0.603, Val loss 0.724\n",
            "Ep 1 (Step 000085): Train loss 0.511, Val loss 0.706\n",
            "Ep 1 (Step 000090): Train loss 0.564, Val loss 0.693\n",
            "Ep 1 (Step 000095): Train loss 0.501, Val loss 0.687\n",
            "Ep 1 (Step 000100): Train loss 0.501, Val loss 0.681\n",
            "Ep 1 (Step 000105): Train loss 0.569, Val loss 0.675\n",
            "Ep 1 (Step 000110): Train loss 0.557, Val loss 0.668\n",
            "Ep 1 (Step 000115): Train loss 0.509, Val loss 0.667\n",
            "Below is an instruction that describes a task.Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task.Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.431, Val loss 0.671\n",
            "Ep 2 (Step 000125): Train loss 0.449, Val loss 0.691\n",
            "Ep 2 (Step 000130): Train loss 0.452, Val loss 0.686\n",
            "Ep 2 (Step 000135): Train loss 0.412, Val loss 0.685\n",
            "Ep 2 (Step 000140): Train loss 0.412, Val loss 0.682\n",
            "Ep 2 (Step 000145): Train loss 0.370, Val loss 0.678\n",
            "Ep 2 (Step 000150): Train loss 0.380, Val loss 0.673\n",
            "Ep 2 (Step 000155): Train loss 0.409, Val loss 0.669\n",
            "Ep 2 (Step 000160): Train loss 0.416, Val loss 0.676\n",
            "Ep 2 (Step 000165): Train loss 0.373, Val loss 0.681\n",
            "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.682\n",
            "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.672\n",
            "Ep 2 (Step 000180): Train loss 0.384, Val loss 0.655\n",
            "Ep 2 (Step 000185): Train loss 0.412, Val loss 0.655\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
            "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.632\n",
            "Ep 2 (Step 000200): Train loss 0.305, Val loss 0.628\n",
            "Ep 2 (Step 000205): Train loss 0.348, Val loss 0.624\n",
            "Ep 2 (Step 000210): Train loss 0.372, Val loss 0.623\n",
            "Ep 2 (Step 000215): Train loss 0.392, Val loss 0.629\n",
            "Ep 2 (Step 000220): Train loss 0.302, Val loss 0.642\n",
            "Ep 2 (Step 000225): Train loss 0.344, Val loss 0.656\n",
            "Ep 2 (Step 000230): Train loss 0.293, Val loss 0.657\n",
            "Below is an instruction that describes a task.Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task.Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "Execution Time: 3.26 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch05 import plot_losses\n",
        "epochs_tensor=torch.linspace(0,num_epochs,len(train_losses))\n",
        "plot_losses(epochs_tensor,tokens_seen,train_losses,val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "xKJeM0C6g-wD",
        "outputId": "a27076e1-199d-48b9-f629-cf468ce2f713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "  input_text=format_input(entry)\n",
        "  token_ids=generate(\n",
        "      model=model,\n",
        "      idx=text_to_token_ids(input_text,tokenizer).to(device),\n",
        "      max_new_tokens=256,\n",
        "      context_size=BASE_CONFIG[\"context_length\"],\n",
        "      eos_id=50256,\n",
        "  )\n",
        "  generated_text=token_ids_to_text(token_ids,tokenizer)\n",
        "  response_text=(\n",
        "      generated_text[len(input_text):].replace('### Response:',\"\").strip()\n",
        "  )\n",
        "  print(input_text)\n",
        "  print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "  print(f\"Generated response:\\n>> {response_text.strip()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM2mLDUnhfeD",
        "outputId": "ea01c38b-a48e-4a4a-8bf2-4a7b271dbaaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "Generated response:\n",
            ">> The car is as fast as a bullet.\n",
            "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "Generated response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "Generated response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "for i,entry in tqdm(enumerate(test_data),total=len(test_data)):\n",
        "  input_text=format_input(entry)\n",
        "  token_ids=generate(\n",
        "      model=model,\n",
        "      idx=text_to_token_ids(input_text,tokenizer).to(device),\n",
        "      max_new_tokens=256,\n",
        "      context_size=BASE_CONFIG[\"context_length\"],\n",
        "      eos_id=50256\n",
        "  )\n",
        "  generated_text=token_ids_to_text(token_ids,tokenizer)\n",
        "  response_text=(\n",
        "      generated_text[len(input_text):].replace('### Response:',\"\").strip()\n",
        "  )\n",
        "  test_data[i][\"model_response\"]=response_text\n",
        "with open(\"instruction-data-with-response.json\",\"w\") as file:\n",
        "  json.dump(test_data,file,indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgwhClLeiyXX",
        "outputId": "43145ca4-6ccf-48de-d674-8b24180d8e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [01:10<00:00,  1.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6oMN178jsZb",
        "outputId": "bd7e7704-b26c-4c40-90da-68f7dc5b6ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZksbTVKjxXc",
        "outputId": "f5df8ed9-bd86-4687-c20a-8e5fa3df69a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ]
    }
  ]
}