{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjHJJ0wSQ2+fdLOAXGLYsw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spandanbhandari/LLMs-from-Scratch/blob/main/finetuningClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jj1lPNLKlkF"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llms-from-scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGARYN-yvTrY",
        "outputId": "f4ae4840-4f72-40a7-fb98-d5558d1387d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llms-from-scratch\n",
            "  Downloading llms_from_scratch-1.0.6-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.6.0+cu124)\n",
            "Collecting jupyterlab>=4.0 (from llms-from-scratch)\n",
            "  Downloading jupyterlab-4.4.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting tiktoken>=0.5.1 (from llms-from-scratch)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (3.10.0)\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.18.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (4.67.1)\n",
            "Requirement already satisfied: numpy<2.1,>=1.26 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.2.2)\n",
            "Collecting pip>=25.0.1 (from llms-from-scratch)\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pytest>=8.3.5 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (8.3.5)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (24.2)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=8.3.5->llms-from-scratch) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=8.3.5->llms-from-scratch) (1.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.32.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.37.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->llms-from-scratch) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.3.0->llms-from-scratch) (1.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->llms-from-scratch) (0.45.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab>=4.0->llms-from-scratch) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab>=4.0->llms-from-scratch) (4.3.7)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (4.23.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->llms-from-scratch) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->llms-from-scratch) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->llms-from-scratch) (3.1.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (21.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (3.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.8.4)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (24.11.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading llms_from_scratch-1.0.6-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.2-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, pip, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, fqdn, async-lru, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, arrow, nvidia-cusolver-cu12, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, llms-from-scratch\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 6.5.7 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n",
            "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.5 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.2 jupyterlab-server-2.27.3 llms-from-scratch-1.0.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 overrides-7.7.0 pip-25.1.1 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 tiktoken-0.9.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(\n",
        "    url,zip_path,extracted_path,data_file_path):\n",
        "  if data_file_path.exists():\n",
        "    print(f\"{data_file_path} already exists.Skipping download\")\n",
        "    return\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "  with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "  original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "  os.rename(original_file_path, data_file_path)\n",
        "  print(f\"File downloaded and saved as {data_file_path}\")\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvAP5qPjwmoW",
        "outputId": "9cbcba04-5357-4253-ff42-7ab0a78462a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(data_file_path,sep='\\t',header=None,names=[\"Label\",\"Text\"])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zGWA1eosxW8p",
        "outputId": "57843e9f-af2f-49c2-d559-e39d942ad716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-151f4540-672b-4691-9540-9bb6d461209f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-151f4540-672b-4691-9540-9bb6d461209f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-151f4540-672b-4691-9540-9bb6d461209f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-151f4540-672b-4691-9540-9bb6d461209f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-faba5f30-d82f-4dc8-aeda-d3f1739b531e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-faba5f30-d82f-4dc8-aeda-d3f1739b531e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-faba5f30-d82f-4dc8-aeda-d3f1739b531e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_32410cec-3618-4700-9d2e-0167aa747173\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_32410cec-3618-4700-9d2e-0167aa747173 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSb9uPORxkyR",
        "outputId": "b2ce0a9b-3767-40c6-8a40-6b1befa2e59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        "  num_spam=df[df[\"Label\"]==\"spam\"].shape[0]\n",
        "  ham_subset=df[df[\"Label\"]==\"ham\"].sample(num_spam,random_state=123)\n",
        "  balanced_df=pd.concat([ham_subset,df[df[\"Label\"]==\"spam\"]])\n",
        "  return balanced_df\n",
        "balanced_df=create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssuasHn-xvTH",
        "outputId": "fd08819f-7d7e-4004-e67b-da24581bd56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"]=balanced_df[\"Label\"].map({ \"ham\":0,\"spam\":1})"
      ],
      "metadata": {
        "id": "9HHTf69IyKP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df,train_frac,validation_frac):\n",
        "  df=df.sample(frac=1,random_state=123).reset_index(drop=True)\n",
        "  train_end=int(len(df)*train_frac)\n",
        "  validation_end=train_end+int(len(df)*validation_frac)\n",
        "\n",
        "  train_df=df[:train_end]\n",
        "  validation_df=df[train_end:validation_end]\n",
        "  test_df=df[validation_end:]\n",
        "  return train_df,validation_df,test_df\n",
        "train_df,validation_df,test_df=random_split(balanced_df,0.7,0.1)"
      ],
      "metadata": {
        "id": "dNBU1FKqySnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\",index=None)\n",
        "validation_df.to_csv(\"validation.csv\",index=None)\n",
        "test_df.to_csv(\"test.csv\",index=None)"
      ],
      "metadata": {
        "id": "tO8aFCGty2q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\",allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImG6e-DgzRCA",
        "outputId": "6159dd99-8751-4b7e-f006-431cd5715ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class SpamDataset(Dataset):\n",
        "  def __init__(self,csv_file,tokenizer,max_length=None,pad_token_id=50256):\n",
        "    self.data=pd.read_csv(csv_file)\n",
        "    self.encoded_texts=[tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
        "    if max_length is None:\n",
        "      self.max_length=self._longest_encoded_length()\n",
        "    else:\n",
        "      self.max_length=max_length\n",
        "      self.encoded_texts=[encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
        "    self.encoded_texts=[encoded_text+[pad_token_id]*(self.max_length-len(encoded_text)) for encoded_text in self.encoded_texts]\n",
        "  def __getitem__(self,index):\n",
        "    encoded=self.encoded_texts[index]\n",
        "    label=self.data.iloc[index][\"Label\"]\n",
        "    return (torch.tensor(encoded,dtype=torch.long),\n",
        "    torch.tensor(label,dtype=torch.long))\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def _longest_encoded_length(self):\n",
        "    max_length=0\n",
        "    for encoded_text in self.encoded_texts:\n",
        "      encoded_length=len(encoded_text)\n",
        "      if encoded_length>max_length:\n",
        "        max_length=encoded_length\n",
        "    return max_length\n"
      ],
      "metadata": {
        "id": "7U2Jn6xszpc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=SpamDataset(csv_file=\"train.csv\",max_length=None,tokenizer=tokenizer)\n",
        "val_dataset=SpamDataset(csv_file=\"validation.csv\",max_length=train_dataset.max_length,tokenizer=tokenizer)\n",
        "test_dataset=SpamDataset(csv_file=\"test.csv\",max_length=train_dataset.max_length,tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "X7SNMr0I1viJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90VPRmCE16tp",
        "outputId": "c950e3b1-8692-46b8-dc83-3721a90c44c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "num_workers=0\n",
        "batch_size=8\n",
        "torch.manual_seed(123)\n",
        "train_loader=DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "val_loader=DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "test_loader=DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "3Pln6_el2TGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch,target_batch in train_loader:\n",
        "  pass\n",
        "print(\"Input batch dimensions:\",input_batch.shape)\n",
        "print(\"Label batch dimensions:\",target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA4U77gH23fA",
        "outputId": "7d1d38d9-854b-44b7-cc2f-b1a43ec401a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KJlzxBo3E6r",
        "outputId": "49f5a396-ac2a-4b80-8b53-12ca2ef72e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL=\"gpt2-small (124M)\"\n",
        "INPUT_PROMPT=\"Every effort moves\"\n",
        "BASE_CONFIG={\n",
        "    \"vocab_size\":50257,\n",
        "    \"context_length\":1024,\n",
        "    \"drop_rate\":0.0,\n",
        "    \"qkv_bias\":True\n",
        "}\n",
        "model_configs={\n",
        "  \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "  \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "  \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "  \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ],
      "metadata": {
        "id": "PdC1yaIH3LQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch05 import download_and_load_gpt2,load_weights_into_gpt\n",
        "from llms_from_scratch.ch04 import GPTModel\n",
        "\n",
        "model_size=CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings,params=download_and_load_gpt2(model_size=model_size,models_dir=\"gpt2\")\n",
        "model=GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model,params)\n",
        "model.eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "2hy9-jjP3wbY",
        "outputId": "4637baff-1385-4976-cfbc-e6cde2c80633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 52.1kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.05MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 116kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:41<00:00, 11.9MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 6.72MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.63MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.55MiB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.eval of GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.nn.modules.module.Module.eval</b><br/>def eval() -&gt; T</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py</a>Set the module in evaluation mode.\n",
              "\n",
              "This has an effect only on certain modules. See the documentation of\n",
              "particular modules for details of their behaviors in training/evaluation\n",
              "mode, i.e. whether they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
              "etc.\n",
              "\n",
              "This is equivalent with :meth:`self.train(False) &lt;torch.nn.Module.train&gt;`.\n",
              "\n",
              "See :ref:`locally-disable-grad-doc` for a comparison between\n",
              "`.eval()` and several similar mechanisms that may be confused with it.\n",
              "\n",
              "Returns:\n",
              "    Module: self</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2846);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch04 import generate_text_simple\n",
        "from llms_from_scratch.ch05 import text_to_token_ids,token_ids_to_text\n",
        "text_1=\"Every effort moves you\"\n",
        "token_ids=generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1,tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICBKOwXL46FG",
        "outputId": "9580cfc0-7938-40ad-a2a0-22c426087ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        " )\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        " )\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuixkg7T5bhq",
        "outputId": "3452824d-123c-4ab6-9c53-c6c141aac82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt3MbDqk6PcV",
        "outputId": "8c14b626-0a2f-431f-bcdf-681d27f90767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad=False"
      ],
      "metadata": {
        "id": "lx3-0ly66xjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "num_classes=2\n",
        "model.out_head=torch.nn.Linear(\n",
        "    in_features=BASE_CONFIG[\"emb_dim\"],\n",
        "    out_features=num_classes\n",
        ")"
      ],
      "metadata": {
        "id": "PabGD0W66zHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "  param.requires_grad=True\n",
        "for param in model.final_norm.parameters():\n",
        "  param.requires_grad=True"
      ],
      "metadata": {
        "id": "ZQs7iCZo7UMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=tokenizer.encode(\"Do you have time\")\n",
        "inputs=torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\",inputs)\n",
        "print(\"Inputs dimensions:\",inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ztXUEX17oWn",
        "outputId": "d30b1c16-bf72-4aef-e452-65fd8d911998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs=model(inputs)\n",
        "print(\"Outputs:\",outputs)\n",
        "print(\"Outputs dimensions:\",outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eHT8rdZ78GM",
        "outputId": "d865e162-e0c8-4345-ed7e-56648ccbbfe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs: tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\",outputs[:,-1,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QooqdnHX8PX5",
        "outputId": "7b5ca223-36d2-497c-a708-3a96354c16c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output toekN:\",outputs[:,-1,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1nIXjKt8wnh",
        "outputId": "5ed15ab1-d5b2-4198-a2b6-a6941b3a0032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output toekN: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probas=torch.softmax(outputs[:,-1,:],dim=-1)\n",
        "label=torch.argmax(probas)\n",
        "print(\"Class label:\",label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY8ni4E582cT",
        "outputId": "ea64d174-e451-4146-b0e2-c8e3fdc9e1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader,model,device,num_batches=None):\n",
        "  model.eval()\n",
        "  correct_predictions,num_examples=0,0\n",
        "  if num_batches is None:\n",
        "    num_batches=len(data_loader)\n",
        "  else:\n",
        "    num_batches=min(num_batches,len(data_loader))\n",
        "  for i,(input_batch,target_batch) in enumerate(data_loader):\n",
        "    if i<num_batches:\n",
        "      input_batch=input_batch.to(device)\n",
        "      target_batch=target_batch.to(device)\n",
        "      with torch.no_grad():\n",
        "        logits=model(input_batch)[:,-1,:]\n",
        "      predicted_labels=torch.argmax(logits,dim=-1)\n",
        "      num_examples+=predicted_labels.shape[0]\n",
        "      correct_predictions+=(\n",
        "          (predicted_labels==target_batch).sum().item()\n",
        "      )\n",
        "    else:\n",
        "      break\n",
        "    return correct_predictions/num_examples"
      ],
      "metadata": {
        "id": "NKRI3szP9HdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_accuracy=calc_accuracy_loader(\n",
        "    train_loader,model,device,num_batches=10\n",
        ")\n",
        "val_accuracy=calc_accuracy_loader(val_loader,model,device,num_batches=10)\n",
        "test_accuracy=calc_accuracy_loader(test_loader,model,device,num_batches=10)\n",
        "print(f\"Train accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_H9TVT6-CD5",
        "outputId": "20b76691-460e-406c-d544-bdefc8a84fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 25.00%\n",
            "Validation accuracy: 50.00%\n",
            "Test accuracy: 62.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch,target_batch,model,device):\n",
        "  input_batch=input_batch.to(device)\n",
        "  target_batch=target_batch.to(device)\n",
        "  logits=model(input_batch)[:,-1,:]\n",
        "  loss=torch.nn.functional.cross_entropy(logits,target_batch)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "oNsPZPXn-9Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
        "  total_loss=0\n",
        "  if len(data_loader)==0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches=len(data_loader)\n",
        "  else:\n",
        "    num_batches=min(num_batches,len(data_loader))\n",
        "  for i,(input_batch,target_batch) in enumerate(data_loader):\n",
        "    if i<num_batches:\n",
        "      loss=calc_loss_batch(input_batch,target_batch,model,device)\n",
        "      total_loss+=loss\n",
        "    else:\n",
        "      break\n",
        "  return total_loss/num_batches"
      ],
      "metadata": {
        "id": "CkJM7nY2_G89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  train_loss=calc_loss_loader(train_loader,model,device,num_batches=5)\n",
        "  val_loss=calc_loss_loader(val_loader,model,device,num_batches=5)\n",
        "  test_loss=calc_loss_loader(test_loader,model,device,num_batches=5)\n",
        "print(f\"Train loss: {train_loss:.4f}\")\n",
        "print(f\"Validation loss: {val_loss:.4f}\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77urapbP_mrj",
        "outputId": "ae7a4c7f-92d5-442d-96e4-3f6036905012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 2.4530\n",
            "Validation loss: 2.5830\n",
            "Test loss: 2.3220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_simple(\n",
        "    model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter\n",
        "):\n",
        "  train_losses,val_losses,train_accs,val_accs=[],[],[],[]\n",
        "  examples_seen,global_step=0,-1\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch,target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss=calc_loss_batch(input_batch,target_batch,model,device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      examples_seen+=input_batch.shape[0]\n",
        "      global_step+=1\n",
        "\n",
        "      if global_step % eval_freq==0:\n",
        "        train_loss,val_loss=evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, \"\n",
        "                      f\"Val loss {val_loss:.3f}\"\n",
        "                )\n",
        "    train_accuracy=calc_accuracy_loader(train_loader,model,device,num_batches=eval_iter)\n",
        "    val_accuracy=calc_accuracy_loader(val_loader,model,device,num_batches=eval_iter)\n",
        "\n",
        "    print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "    print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "    train_accs.append(train_accuracy)\n",
        "    val_accs.append(val_accuracy)\n",
        "  return train_losses,val_losses,train_accs,val_accs,examples_seen\n"
      ],
      "metadata": {
        "id": "eOP0dJeIASHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss=calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
        "    val_loss=calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
        "  model.train()\n",
        "  return train_loss,val_loss"
      ],
      "metadata": {
        "id": "UzVYG_F6BjTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time=time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer=torch.optim.AdamW(model.parameters(),lr=5e-3,weight_decay=0.01)\n",
        "num_epochs=3\n",
        "train_losses,val_losses,train_accs,val_accs,examples_seen=train_classifier_simple(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    device,\n",
        "    num_epochs=num_epochs,\n",
        "    eval_freq=50,\n",
        "    eval_iter=5\n",
        ")\n",
        "end_time=time.time()\n",
        "execution_time_minutes=(end_time-start_time)/60\n",
        "print(f\"Training took {execution_time_minutes:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFJ8uGPjB7_v",
        "outputId": "63c7b6c6-79d4-466f-8b3e-a41b7b01868e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 0.069, Val loss 0.114\n",
            "Ep 1 (Step 000050): Train loss 0.044, Val loss 0.017\n",
            "Ep 1 (Step 000100): Train loss 0.011, Val loss 0.019\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Ep 2 (Step 000150): Train loss 0.051, Val loss 0.067\n",
            "Ep 2 (Step 000200): Train loss 0.000, Val loss 0.000\n",
            "Ep 2 (Step 000250): Train loss 0.056, Val loss 0.061\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Ep 3 (Step 000300): Train loss 0.000, Val loss 0.307\n",
            "Ep 3 (Step 000350): Train loss 0.081, Val loss 0.153\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training took 0.58 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_values(\n",
        "        epochs_seen, examples_seen, train_values, val_values,\n",
        "        label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        " #1\n",
        "    ax1.plot(epochs_seen.cpu().numpy(), [t.cpu().item() for t in train_values], label=f\"Training {label}\") # Move epochs_seen and train_values to CPU before plotting\n",
        "    ax1.plot(\n",
        "        epochs_seen.cpu().numpy(), [t.cpu().item() for t in val_values], linestyle=\"-.\", # Move epochs_seen and val_values to CPU before plotting\n",
        "        label=f\"Validation {label}\"\n",
        "    )\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        " #2\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(examples_seen.cpu().numpy(), [t.cpu().item() for t in train_values], alpha=0)    # Move examples_seen and train_values to CPU before plotting #3\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "    fig.tight_layout()             #4\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "amQqoOtGE7lZ",
        "outputId": "84894183-2ec9-4005-bed2-ff95396d5a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXH_Ac4AGMZa",
        "outputId": "eaa83a9c-ba20-4b14-8006-7e4d2f4b516f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 100.00%\n",
            "Validation accuracy: 100.00%\n",
            "Test accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(text,model,tokenizer,device,max_length=None,pad_token_id=50256):\n",
        "  model.eval()\n",
        "  input_ids=tokenizer.encode(text)\n",
        "  supported_context_length=model.pos_emb.weight.shape[1]\n",
        "  input_ids=input_ids[:min(max_length,supported_context_length)]\n",
        "  input_ids+=[pad_token_id]*(max_length-len(input_ids))\n",
        "  input_tensor=torch.tensor(input_ids,device=device).unsqueeze(0)\n",
        "  with torch.no_grad():\n",
        "    logits=model(input_tensor)[:,-1,:]\n",
        "  predicted_label=torch.argmax(logits,dim=-1).item()\n",
        "  return \"spam\" if predicted_label==1 else \"not spam\""
      ],
      "metadata": {
        "id": "P-SEn_nwHQ33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1=(\"You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\")\n",
        "print(classify_review(text_1,model,tokenizer,device,max_length=train_dataset.max_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u-bxW4sIBL0",
        "outputId": "f193fec8-e695-4a16-a39f-af8c2e731ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2=(\"Hey, just wanted to check if we're still on for dinner tonight? Let me know!\")\n",
        "print(classify_review(text_2,model,tokenizer,device,max_length=train_dataset.max_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY0GFbBaIX5X",
        "outputId": "3b594d36-6655-4ced-a920-18f20d14a20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "69__HTagIlia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict=torch.load(\"review_classifier.pth\",map_location=device)\n",
        "model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WsVFp4NItIu",
        "outputId": "13f6ffcb-cec2-4ee4-e797-c04db55bc0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}